\chapter{Introduction}

This dissertation introduces novel methods for robotic simulation, planning, and control based on differentiable convex modeling.
By formulating algorithms in these domains in an optimization-first framework, we are often able to simplify the complexity of the algorithm and offload computational complexity to highly specialized and efficient solvers.
This dissertation focuses on extending many of these methods with advances in modern convex modeling, where solvers are capable of delivering globally optimal solutions to convex optimization problems while maintaining full differentiability.
Since these solvers are fast, robust, and differentiable, they can be treated the same as more traditional numerical linear algebra routines such as those used to solve linear systems \cite{boyd2004}.
Using convex modeling as a building block for novel algorithm development enables simple, performant, and flexible algorithms. 

In the period between 1939 and 1948, Leonid Kantorovic, George Dantzig, and John Von Neumann, introduced the fundamental concepts in constrained optimization surrounding linear programming and duality \cite{dantzig1990}.
Around the same time, the Karush–Kuhn–Tucker (KKT) conditions were established that gave clarity to what it means for a solution to a constrained optimization problem to be ``optimal'' \cite{boyd2004}.
While practictioners focused on implementing numerical optimization algorithms on newly introduced computers, theorists turned their attention towards a useful taxonomy for the world of constrained optimization.
In 1983, Soviet scientists Nemirovski and Yudin made the first formal argument that there was, in fact, a substantial difference in the problem complexity between solving convex optimization problems and general nonlinear optimization problems \cite{blair1985}.
The 1980s also saw the advent of robust interior-point methods that were capable of solving general convex optimization problems in polynomial time \cite{mehrotra1992}. 
With advances in numerical linear algebra, algorithmic developments, and faster computers, by the 2000's convex optimization was mature and ready for everyday use.
Modeling tools such as CVX \cite{grant}, CVXPY \cite{diamond} and Convex.jl \cite{udell2014} made convex optimization accessible by taking problems described in natural mathematical syntax and solving them with commercial and open source solvers. 
In the late 2010s, the works of \cite{amos2017} and \cite{agrawal2019} enabled the differentiation of well-defined convex optimization problems with respect to generic problem parameters.
Today, convex optimization solvers can be treated as well-understood and reliable differentiable functions for use in a wide range of applications. 

% % commented out until I actually do it 
% In the background section in Chapter \ref{sec:background}, fundamental concepts in numerical optimization, convex optimization, and differentiable optimization are introduced.
% Notation and standard formulations of common problems are introduced, and a state-of-the-art primal-dual interior point solver is detailed. 
% All of the works presented in this dissertation utilize this specific solver, as it is fast, numerically robust, and with a slight modification allows for smooth derivatives.
% The process of initializing, forming, and solving convex optimization problems is discussed. 

In Chapter \ref{sec:cpeg1}, a classical guidance framework for atmospheric entry dating back to the Apollo program is updated to incorporate convex optimization that results in state-of-the-art performance. 
The dynamics of an entry vehicle in an arbitrary atmosphere is discussed in \ref{sec:cpeg1:dynamics} in a form that is less popular in the literature but more amenable to numerical optimization.
From this, the novel Convex Predictor-corrector Entry Guidance (CPEG) algorithm for atmospheric guidance is detailed that is built on convex optimization in \ref{sec:cpeg1:cpeg}.
The performance of CPEG is demonstrated on a realistic set of initial conditions, and convergence is then validated in \ref{sec:cpeg1:experiments}. 

Chapter \ref{sec:cpeg2} expands on Chapter \ref{sec:cpeg1} by introducing an updated variant of CPEG that is capable of directly reasoning about atmospheric uncertainty during entry.
The guidance framework present in CPEG is enhanced with an estimator capable of atmospheric estimation and adjustments are made to the controller-estimator stack to enable robust real-time control of the vehicles.
Results for this algorithm are shown on realistic Martian atmospheres and an ablation study validates the importance of the atmospheric adaptation. 

Chapter \ref{sec:wigglesat} utilizes a convex optimization-based motion planner that enables precise control of nanosatellite space telescopes through actuation of weighted booms.
Traditionally, spacecraft control pointing with onboard reaction wheels. These rotors are spun up and down to transfer angular momentum to and from the nanosatellite.
Due to imperfections in these wheels, vibrations are transmitted to the telescope resulting in poor image quality.  
This chapter introduces a new actuation strategy based on slow-spinning long booms, a noted departure from the more common fast-spinning reaction wheels. Armed with the knowledge of the nanosatellite's orbit and the Earth's magnetic field, a convex motion planner is able to directly reason about future disturbances to enable precise attitude using just the booms. 
This technique is demonstrated on a precise space telescope that must take long exposure during eclipse periods without the booms hitting their actuation limits. 

Chapter \ref{sec:dcol} presents a new approach for collision detection that enables a uniform framework and smooth differentiability. Traditionally, collision detection between two convex shapes is performed by solving for the closest point between the shapes. This problem is well defined and easy to solve for many of the common convex primitives, but is non-differentiable and is force to default to a different algorithm when the shapes are in contact. Our method for detecting these collisions utilizes a different framework: the minimum uniform scaling between the two shapes that results in an intersection is solved for with convex optimization. This problem is small, guaranteed to be well defined, and has no degenerate cases. The solution to the resulting convex optimization problem is smooth and differentiable no matter the configuration of the objects, and is used to specify collision avoidance constraints in representative motion planning examples. 

Chapter \ref{sec:cdcol} introduces an extension to Chapter \ref{sec:dcol} by exploiting the same framework for use in continuous collision detection. Discrete collision detection checks two static convex shapes for collisions, whereas continuous collision detection must reason about the same problem when the shapes are moving. Traditionally, the transition from discrete to continuous collision detection involves significant modifications to the algorithm with added limitations. Alternatively, the framework from Chapter \ref{sec:dcol} is augmented with a time parameter, and another well-defined convex optimization problem is used to solve for continuous collision information. Again, this method is fully differentiable and demonstrated on collision-free motion planning examples where discrete collision detection is insufficient for avoiding contact. 

Chapter \ref{sec:plugging} details a simple and efficient framework for learning generalized linear models online as it relates to connector insertion. In this application, the insertion of a male connector into a female socket presents a challenging environment to model in simulation due to the deformation of the materials, the tightness of the fit, and the unknown friction properties. To avoid learning a full dynamics simulator, this work simply learns the relationship between the control signal, the estimated state, and a wrist-mounted force torque sensor. This relationship is represented with a generalized linear model, making the model learning problem convex and well defined. To solve this problem online in a recursive fashion, the Linear Model Learning (LML) algorithm is developed to learn the globally optimal estimated model using only matrix-vector operations. In the absence of any matrix inversions, this algorithm scales very favorably on a GPU, enabling fast and efficient model learning even with large-scale linear models. 

Chapter \ref{sec:quasidynamics} examines the performance of quasistatic simulation on rigid point clouds, and extends a common formulation to include the necessary torsional friction for realistic contact-rich manipulation. When contact with a rigid point cloud is made in rigid-body dynamics, the single point contact does not allow for the true torsional friction that comes from the type of patch contacts present in reality. To account for this, a modification is made to an optimization-based simulation framework to naturally account for this with a torsional friction term that is proportional to the normal force. The resulting simulation steps are computed with convex optimization and are therefore fully differentiable. The resulting simulator is used to grasp high-fidelity point clouds with realistic contact dynamics. 

Chapter \ref{sec:bundles} introduces the trajectory bundle method for highly accurate trajectory optimization with black-box simulators, costs, and constraints.  Existing methods for model-based trajectory optimization have access to derivatives of all cost, dynamics, and constraint functions presented in the problem. In many cases, this is a reasonable assumption, but for many challenging robotics tasks such as those involving nonsmooth contact interactions, these derivatives can be unavailable, expensive to compute, or unreliable. To combat this, the trajectory bundle method approximates these functions by interpolating samples centered on the current iterate. This method of approximation by interpolation is derivative-free and results in a linearization different from a standard first-order Taylor-series. Using this approximation, a convex optimization problem is posed that minimizes over these interpolants to compute a step direction, and the process is repeated until convergence.

With differentiable convex optimization as a robust technology, this dissertation is able to contribute simple and performant algorithms to multiple domains within robotics with guarantees of predictable and safe performance. By reformulating these problems in an optimization-first way, the resulting algorithms are often simpler and more performant than without, all while being modular and configurable.

% \newpage
% \section{Summary of open source contributions}
% The code and experiments developed for this thesis
% are free and open-source:

% \begin{itemize}
% \item \url{https://github.com/locuslab/icnn}:
%   TensorFlow experiments for the input-convex neural networks
%   work presented in \cref{sec:icnn}.
% \item \url{https://locuslab.github.io/qpth/} and
%   \url{https://github.com/locuslab/qpth}:
%   A stand-alone PyTorch library for the OptNet QP layers presented
%   in \cref{sec:optnet}.
% \item \url{https://github.com/locuslab/optnet}:
%   PyTorch experiments for the OptNet work
%   presented in \cref{sec:optnet}.
% \item \url{https://locuslab.github.io/mpc.pytorch}
%   and \url{https://github.com/locuslab/mpc.pytorch}:
%   A stand-alone PyTorch library for the differentiable
%   model predictive control approach presented in
%   \cref{sec:empc}.
% \item \url{https://github.com/locuslab/differentiable-mpc}:
%   PyTorch experiments for the differentiable MPC work
%   presented in \cref{sec:empc}.
% \end{itemize}

% \vspace{5mm}
% \noindent
% I have also created the following open source
% projects during my Ph.D.:
% \begin{itemize}
% \item \url{https://github.com/bamos/block}:
%   An intelligent block matrix library for numpy, PyTorch, and beyond.
% \item \url{https://github.com/bamos/dcgan-completion.tensorflow}:
%   Image Completion with Deep Learning in TensorFlow.
% \item \url{https://github.com/cmusatyalab/openface}:
%   Face recognition with deep neural networks.
% \item \url{https://github.com/bamos/densenet.pytorch}:
%   A PyTorch implementation of DenseNet.
% \end{itemize}

\newpage
\section{Summary of publications}
\newcommand{\fcite}[1]{
  \begin{leftbar}
  \begin{quote}%
    \citep{#1} \fullcite{#1}
  \end{quote}
  \end{leftbar}}

\noindent The content of \cref{sec:qpax} appears in:
\fcite{tracy2024}
\vspace{5mm}

\noindent The content of \cref{sec:cpeg1} appears in:
\fcite{tracy2022c}
\vspace{5mm}

\noindent The content of \cref{sec:cpeg2} appears in:
\fcite{tracy2023}
\vspace{5mm}

\noindent The content of \cref{sec:wigglesat} appears in:
\fcite{tracy2022a}
\vspace{5mm}

\noindent The content of \cref{sec:dcol} appears in:
\fcite{tracy2023b}
\vspace{5mm}

\noindent The content of \cref{sec:plugging} appears in:
\fcite{tracy2023d}
\vspace{5mm}

\noindent The content of \cref{sec:quasidynamics} appears in:
\fcite{tracy2023c}
\vspace{5mm}

\noindent
\textbf{Non-thesis research:}
During my Ph.D., I have conducted research on topics that do not appear in this thesis. Publications involving these topics are below. 

\begin{leftbar}
\begin{quote}%
  \citep{tracy2020} \fullcite{tracy2020} \\[5mm]
  \citep{tracy2021} \fullcite{tracy2021} \\[5mm]
  \citep{tracy2022f} \fullcite{tracy2022f} \\[5mm]
  \citep{tracy2022} \fullcite{tracy2022} 
\end{quote}
\end{leftbar}

\vspace{7mm}
\noindent
I have also been fortunate enough to work on the following publications alongside my collaborators as a non-primary author.

\begin{leftbar}
\begin{quote}%
  \fullcite{douglas2021} \\[5mm]
  \fullcite{jackson2021b} \\[5mm]
  \fullcite{jackson2021} \\[5mm]
  \fullcite{holliday22} \\[5mm]
  \fullcite{bishop2024} 
\end{quote}
\end{leftbar}



%%% Local Variables:
%%% coding: utf-8
%%% mode: latex
%%% TeX-engine: xetex
%%% TeX-master: "../thesis"
%%% End: